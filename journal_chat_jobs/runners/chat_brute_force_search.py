import asyncio
from dataclasses import dataclass
import json
import random
import secrets
import string
import time
from typing import (
    AsyncIterable,
    Awaitable,
    Callable,
    Dict,
    List,
    Literal,
    Optional,
    Set,
    Tuple,
    TypeVar,
    Union,
    cast,
    TypedDict,
)

import pytz
from itgs import Itgs
from journal_chat_jobs.lib.journal_chat_job_context import JournalChatJobContext
from lib.image_files.image_file_ref import ImageFileRef
from lib.journals.journal_chat import JournalChat
from lib.journals.journal_chat_redis_packet import (
    EventBatchPacketDataItemDataError,
    EventBatchPacketDataItemDataThinkingBar,
    EventBatchPacketDataItemDataThinkingSpinner,
    JournalChatRedisPacketMutations,
    JournalChatRedisPacketPassthrough,
    SegmentDataMutation,
)
from lib.journals.journal_entry_item_data import (
    JournalEntryItemData,
    JournalEntryItemDataClient,
    JournalEntryItemDataDataTextual,
    JournalEntryItemDataDataTextualClient,
    JournalEntryItemTextualPartJourney,
    JournalEntryItemTextualPartJourneyClient,
    JournalEntryItemTextualPartJourneyClientDetails,
    JournalEntryItemTextualPartParagraph,
    MinimalJourneyInstructor,
)
from lib.transcripts.cache import get_transcript
import gzip

from lib.journals.publish_journal_chat_event import publish_journal_chat_event
from lib.journals.serialize_journal_chat_event import serialize_journal_chat_event
from lib.redis_stats_preparer import RedisStatsPreparer
from lib.transcripts.model import Transcript
from lib.users.timezones import get_user_timezone
from lib.journals.journal_stats import JournalStats
from redis_helpers.journal_chat_job_finish import safe_journal_chat_job_finish
import unix_dates
import openai
import os
import lib.users.entitlements
import lib.image_files.auth


class TechniqueParameters(TypedDict):
    type: Literal["llm"]
    platform: Literal["openai"]
    model: str


TECHNIQUE_PARAMETERS = cast(
    TechniqueParameters,
    {
        "type": "llm",
        "platform": "openai",
        "model": "gpt-4o",
    },
)


async def handle_chat(itgs: Itgs, ctx: JournalChatJobContext) -> None:
    """This is a relatively simple, toy implementation for how to generate the
    system response to the users message. It evaluates every journey against the
    message to get a 1-10 score (1 openai query per journey), then for all within
    2 of the top score, does N LOG(N) queries to compare them against each other
    to find the best. It does this whole process once for pro and once for non-pro
    journeys, so it always returns a pro journey and a non-pro journey

    When `replace_index` is None, this responds to the conversation of the the
    current point, where presumably the last message in the conversation is from
    the user.

    Alternatively, if `replace_index` is set, replaces the message at that index
    with a new response from the system. This will only work well if the item being
    replaced was also generated by this function
    """
    assert ctx.task.replace_index is None or (
        ctx.task.replace_index >= 0
        and ctx.task.replace_index < len(ctx.task.conversation)
    ), "bad replace index"

    stats = JournalStats(RedisStatsPreparer())
    try:
        conn = await itgs.conn()
        cursor = conn.cursor("weak")

        responses = await cursor.executeunified3(
            (
                ("SELECT given_name FROM users WHERE sub=?", [ctx.user_sub]),
                (
                    "SELECT 1 FROM journal_entries, users WHERE journal_entries.uid = ? AND journal_entries.user_id = users.id AND users.sub = ?",
                    [ctx.journal_entry_uid, ctx.user_sub],
                ),
                *(
                    []
                    if ctx.task.replace_index is None
                    else [
                        (
                            "SELECT journal_entry_items.uid FROM journal_entry_items, journal_entries WHERE journal_entries.uid = ? AND journal_entry_items.journal_entry_id = journal_entries.id AND journal_entry_items.entry_counter = ?",
                            [ctx.journal_entry_uid, ctx.task.replace_index + 1],
                        )
                    ]
                ),
            ),
            transaction=True,
        )

        if not responses[0].results:
            stats.incr_system_chats_failed_internal(
                unix_date=ctx.queued_at_unix_date_in_stats_tz,
                **TECHNIQUE_PARAMETERS,
                prompt_identifier="preparation",
                category="internal",
            )
            event_at = time.time()
            await safe_journal_chat_job_finish(
                itgs,
                journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
                log_id=ctx.log_id.encode("utf-8"),
                last_event=serialize_journal_chat_event(
                    journal_master_key=ctx.journal_master_key,
                    event=JournalChatRedisPacketPassthrough(
                        counter=ctx.reserve_event_counter(),
                        type="passthrough",
                        event=EventBatchPacketDataItemDataError(
                            type="error",
                            message="Failed to create response",
                            detail="user not found",
                        ),
                    ),
                    now=event_at,
                ),
                now=int(event_at),
            )
            raise ValueError(f"User {ctx.user_sub} not found")

        if not responses[1].results:
            stats.incr_system_chats_failed_internal(
                unix_date=ctx.queued_at_unix_date_in_stats_tz,
                **TECHNIQUE_PARAMETERS,
                prompt_identifier="preparation",
                category="internal",
            )
            event_at = time.time()
            await safe_journal_chat_job_finish(
                itgs,
                journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
                log_id=ctx.log_id.encode("utf-8"),
                last_event=serialize_journal_chat_event(
                    journal_master_key=ctx.journal_master_key,
                    event=JournalChatRedisPacketPassthrough(
                        counter=ctx.reserve_event_counter(),
                        type="passthrough",
                        event=EventBatchPacketDataItemDataError(
                            type="error",
                            message="Failed to create response",
                            detail="journal entry not found",
                        ),
                    ),
                    now=event_at,
                ),
                now=int(event_at),
            )
            raise ValueError(
                f"Journal entry {ctx.journal_entry_uid} not found or not for {ctx.user_sub}"
            )

        given_name = cast(Optional[str], responses[0].results[0][0])
        if ctx.task.replace_index is None:
            replace_journal_entry_uid = None
        else:
            if not responses[2].results:
                stats.incr_system_chats_failed_internal(
                    unix_date=ctx.queued_at_unix_date_in_stats_tz,
                    **TECHNIQUE_PARAMETERS,
                    prompt_identifier="preparation",
                    category="internal",
                )
                event_at = time.time()
                await safe_journal_chat_job_finish(
                    itgs,
                    journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
                    log_id=ctx.log_id.encode("utf-8"),
                    last_event=serialize_journal_chat_event(
                        journal_master_key=ctx.journal_master_key,
                        event=JournalChatRedisPacketPassthrough(
                            counter=ctx.reserve_event_counter(),
                            type="passthrough",
                            event=EventBatchPacketDataItemDataError(
                                type="error",
                                message="Failed to create response",
                                detail="journal entry item not found",
                            ),
                        ),
                        now=event_at,
                    ),
                    now=int(event_at),
                )
                raise ValueError(
                    f"Journal entry {ctx.journal_entry_uid} has no item at index {ctx.task.replace_index} (i.e., with counter {ctx.task.replace_index + 1})"
                )
            replace_journal_entry_uid = responses[2].results[0][0]

        greeting = ctx.task.conversation[-2]
        user_message = ctx.task.conversation[-1]

        user_tz = await get_user_timezone(itgs, user_sub=ctx.user_sub)

        seen_final = False
        async for item in _response_pipeline(
            itgs, ctx=ctx, greeting=greeting, user_message=user_message, stats=stats
        ):
            assert not seen_final, "final message must be last"
            if item[0] is None:
                message = item[1]
                event_at = time.time()
                await safe_journal_chat_job_finish(
                    itgs,
                    journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
                    log_id=ctx.log_id.encode("utf-8"),
                    last_event=serialize_journal_chat_event(
                        journal_master_key=ctx.journal_master_key,
                        event=JournalChatRedisPacketPassthrough(
                            counter=ctx.reserve_event_counter(),
                            type="passthrough",
                            event=message,
                        ),
                        now=event_at,
                    ),
                    now=int(event_at),
                )
                return

            is_final, message, message_client = item
            if is_final:
                seen_final = True

            replace_journal_entry_uid = await _write_journal_entry_item(
                itgs,
                user_tz=user_tz,
                ctx=ctx,
                message=message,
                stats=stats,
                replace_journal_entry_uid=replace_journal_entry_uid,
            )
            chat_state = JournalChat(
                uid=ctx.journal_chat_uid, integrity="", data=[message_client]
            )
            chat_state.integrity = chat_state.compute_integrity()

            event_at = time.time()
            event = serialize_journal_chat_event(
                journal_master_key=ctx.journal_master_key,
                event=JournalChatRedisPacketMutations(
                    counter=ctx.reserve_event_counter(),
                    type="mutations",
                    mutations=[SegmentDataMutation(key=[], value=chat_state)],
                    more=not is_final,
                ),
                now=event_at,
            )

            if is_final:
                continue

            await publish_journal_chat_event(
                itgs, journal_chat_uid=ctx.journal_chat_uid, event=event
            )

        assert seen_final, "final message must be last"

        await safe_journal_chat_job_finish(
            itgs,
            journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
            log_id=ctx.log_id.encode("utf-8"),
            last_event=event,
            now=int(event_at),
        )
        stats.incr_system_chats_succeeded(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="chat_brute_force_search",
        )
    finally:
        await stats.stats.store(itgs)


def _message_from_text(
    text: str,
) -> Tuple[JournalEntryItemData, JournalEntryItemDataClient]:
    paragraphs = [p.strip() for p in text.split("\n")]
    paragraphs = [p for p in paragraphs if p]
    return _message_from_paragraphs(paragraphs)


def _message_from_paragraphs(
    paragraphs: List[str],
) -> Tuple[JournalEntryItemData, JournalEntryItemDataClient]:
    return JournalEntryItemData(
        type="chat",
        data=JournalEntryItemDataDataTextual(
            type="textual",
            parts=[
                JournalEntryItemTextualPartParagraph(
                    type="paragraph",
                    value=p,
                )
                for p in paragraphs
            ],
        ),
        display_author="other",
    ), JournalEntryItemDataClient(
        type="chat",
        data=JournalEntryItemDataDataTextualClient(
            type="textual",
            parts=[
                JournalEntryItemTextualPartParagraph(
                    type="paragraph",
                    value=p,
                )
                for p in paragraphs
            ],
        ),
        display_author="other",
    )


async def _spinner(
    itgs: Itgs,
    /,
    *,
    ctx: JournalChatJobContext,
    message: str,
    detail: Optional[str] = None,
) -> None:
    event_at = time.time()
    await publish_journal_chat_event(
        itgs,
        journal_chat_uid=ctx.journal_chat_uid,
        event=serialize_journal_chat_event(
            journal_master_key=ctx.journal_master_key,
            event=JournalChatRedisPacketPassthrough(
                counter=ctx.reserve_event_counter(),
                type="passthrough",
                event=EventBatchPacketDataItemDataThinkingSpinner(
                    type="thinking-spinner", message=message, detail=detail
                ),
            ),
            now=event_at,
        ),
    )


async def _pbar(
    itgs: Itgs,
    /,
    *,
    ctx: JournalChatJobContext,
    message: str,
    detail: Optional[str] = None,
    at: int,
    of: int,
) -> None:
    event_at = time.time()
    await publish_journal_chat_event(
        itgs,
        journal_chat_uid=ctx.journal_chat_uid,
        event=serialize_journal_chat_event(
            journal_master_key=ctx.journal_master_key,
            event=JournalChatRedisPacketPassthrough(
                counter=ctx.reserve_event_counter(),
                type="passthrough",
                event=EventBatchPacketDataItemDataThinkingBar(
                    type="thinking-bar", message=message, detail=detail, at=at, of=of
                ),
            ),
            now=event_at,
        ),
    )


async def _write_journal_entry_item(
    itgs: Itgs,
    /,
    *,
    user_tz: pytz.BaseTzInfo,
    ctx: JournalChatJobContext,
    message: JournalEntryItemData,
    stats: JournalStats,
    replace_journal_entry_uid: Optional[str] = None,
) -> str:
    if replace_journal_entry_uid is None:
        return await _insert_journal_entry_item(
            itgs,
            user_tz=user_tz,
            ctx=ctx,
            message=message,
            stats=stats,
        )
    await _replace_journal_entry_item(
        itgs,
        user_tz=user_tz,
        ctx=ctx,
        message=message,
        replace_journal_entry_uid=replace_journal_entry_uid,
        stats=stats,
    )
    return replace_journal_entry_uid


async def _insert_journal_entry_item(
    itgs: Itgs,
    /,
    *,
    user_tz: pytz.BaseTzInfo,
    ctx: JournalChatJobContext,
    message: JournalEntryItemData,
    stats: JournalStats,
) -> str:
    conn = await itgs.conn()
    cursor = conn.cursor()

    created_at = time.time()
    created_unix_date_in_user_tz = unix_dates.unix_timestamp_to_unix_date(
        created_at, tz=user_tz
    )

    master_encrypted_data = ctx.journal_master_key.journal_master_key.encrypt(
        gzip.compress(
            message.__pydantic_serializer__.to_json(message),
            compresslevel=9,
            mtime=0,
        )
    ).decode("ascii")

    new_journal_entry_item_uid = f"oseh_jei_{secrets.token_urlsafe(16)}"
    new_journal_entry_counter = len(ctx.task.conversation) + 1
    responses = await cursor.executeunified3(
        (
            (
                "SELECT 1 FROM journal_entries WHERE uid=?",
                (ctx.journal_entry_uid,),
            ),
            (
                "SELECT 1 FROM user_journal_master_keys WHERE uid=?",
                (ctx.journal_master_key.journal_master_key_uid,),
            ),
            (
                """
INSERT INTO journal_entry_items (
uid, 
journal_entry_id, 
entry_counter, 
user_journal_master_key_id,
master_encrypted_data, 
created_at, 
created_unix_date
)
SELECT ?, journal_entries.id, ?, user_journal_master_keys.id, ?, ?, ?
FROM journal_entries, user_journal_master_keys
WHERE
journal_entries.uid = ?
AND user_journal_master_keys.uid = ?
                """,
                (
                    new_journal_entry_item_uid,
                    new_journal_entry_counter,
                    master_encrypted_data,
                    created_at,
                    created_unix_date_in_user_tz,
                    ctx.journal_entry_uid,
                    ctx.journal_master_key.journal_master_key_uid,
                ),
            ),
        ),
        transaction=True,
    )

    if not responses[0].results:
        assert (
            responses[2].rows_affected is None or responses[2].rows_affected < 1
        ), responses
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="insert_failed:journal_entry_not_found",
            category="internal",
        )
        event_at = time.time()
        await safe_journal_chat_job_finish(
            itgs,
            journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
            log_id=ctx.log_id.encode("utf-8"),
            last_event=serialize_journal_chat_event(
                journal_master_key=ctx.journal_master_key,
                event=JournalChatRedisPacketPassthrough(
                    counter=ctx.reserve_event_counter(),
                    type="passthrough",
                    event=EventBatchPacketDataItemDataError(
                        type="error",
                        message="Failed to insert journal entry item",
                        detail="journal entry not found",
                    ),
                ),
                now=event_at,
            ),
            now=int(event_at),
        )
        raise ValueError(f"Journal entry {ctx.journal_entry_uid} not found")
    if not responses[1].results:
        assert (
            responses[2].rows_affected is None or responses[2].rows_affected < 1
        ), responses
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="insert_failed:journal_master_key_not_found",
            category="encryption",
        )
        event_at = time.time()
        await safe_journal_chat_job_finish(
            itgs,
            journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
            log_id=ctx.log_id.encode("utf-8"),
            last_event=serialize_journal_chat_event(
                journal_master_key=ctx.journal_master_key,
                event=JournalChatRedisPacketPassthrough(
                    counter=ctx.reserve_event_counter(),
                    type="passthrough",
                    event=EventBatchPacketDataItemDataError(
                        type="error",
                        message="Failed to insert journal entry item",
                        detail="internal encryption error",
                    ),
                ),
                now=event_at,
            ),
            now=int(event_at),
        )
        raise ValueError(
            f"Journal master key {ctx.journal_master_key.journal_master_key_uid} not found"
        )
    if responses[2].rows_affected is None or responses[2].rows_affected < 1:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="insert_failed:unknown",
            category="internal",
        )
        event_at = time.time()
        await safe_journal_chat_job_finish(
            itgs,
            journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
            log_id=ctx.log_id.encode("utf-8"),
            last_event=serialize_journal_chat_event(
                journal_master_key=ctx.journal_master_key,
                event=JournalChatRedisPacketPassthrough(
                    counter=ctx.reserve_event_counter(),
                    type="passthrough",
                    event=EventBatchPacketDataItemDataError(
                        type="error",
                        message="Failed to insert journal entry item",
                        detail="unknown",
                    ),
                ),
                now=event_at,
            ),
            now=int(event_at),
        )
        raise ValueError("Failed to insert new journal entry item")

    return new_journal_entry_item_uid


async def _replace_journal_entry_item(
    itgs: Itgs,
    /,
    *,
    user_tz: pytz.BaseTzInfo,
    ctx: JournalChatJobContext,
    message: JournalEntryItemData,
    replace_journal_entry_uid: str,
    stats: JournalStats,
) -> None:
    conn = await itgs.conn()
    cursor = conn.cursor()

    created_at = time.time()
    created_unix_date_in_user_tz = unix_dates.unix_timestamp_to_unix_date(
        created_at, tz=user_tz
    )

    master_encrypted_data = ctx.journal_master_key.journal_master_key.encrypt(
        gzip.compress(
            message.__pydantic_serializer__.to_json(message),
            compresslevel=9,
            mtime=0,
        )
    ).decode("ascii")

    responses = await cursor.executeunified3(
        (
            (
                "SELECT 1 FROM journal_entry_items WHERE uid=?",
                (replace_journal_entry_uid,),
            ),
            (
                "SELECT 1 FROM user_journal_master_keys WHERE uid=?",
                (ctx.journal_master_key.journal_master_key_uid,),
            ),
            (
                """
UPDATE journal_entry_items
SET
user_journal_master_key_id = user_journal_master_keys.id,
master_encrypted_data = ?
FROM user_journal_master_keys
WHERE
user_journal_master_keys.uid = ?
AND journal_entry_items.uid = ?
                """,
                (
                    master_encrypted_data,
                    ctx.journal_master_key.journal_master_key_uid,
                    replace_journal_entry_uid,
                ),
            ),
        )
    )

    if not responses[0].results:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="replace_failed:journal_entry_item_not_found",
            category="internal",
        )
        event_at = time.time()
        await safe_journal_chat_job_finish(
            itgs,
            journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
            log_id=ctx.log_id.encode("utf-8"),
            last_event=serialize_journal_chat_event(
                journal_master_key=ctx.journal_master_key,
                event=JournalChatRedisPacketPassthrough(
                    counter=ctx.reserve_event_counter(),
                    type="passthrough",
                    event=EventBatchPacketDataItemDataError(
                        type="error",
                        message="Failed to replace journal entry item",
                        detail="journal entry item not found",
                    ),
                ),
                now=event_at,
            ),
            now=int(event_at),
        )
        raise ValueError(f"Journal entry item {replace_journal_entry_uid} not found")

    if not responses[1].results:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="replace_failed:journal_master_key_not_found",
            category="encryption",
        )
        event_at = time.time()
        await safe_journal_chat_job_finish(
            itgs,
            journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
            log_id=ctx.log_id.encode("utf-8"),
            last_event=serialize_journal_chat_event(
                journal_master_key=ctx.journal_master_key,
                event=JournalChatRedisPacketPassthrough(
                    counter=ctx.reserve_event_counter(),
                    type="passthrough",
                    event=EventBatchPacketDataItemDataError(
                        type="error",
                        message="Failed to replace journal entry item",
                        detail="internal encryption error",
                    ),
                ),
                now=event_at,
            ),
            now=int(event_at),
        )
        raise ValueError(
            f"Journal master key {ctx.journal_master_key.journal_master_key_uid} not found"
        )

    if responses[2].rows_affected is None or responses[2].rows_affected < 1:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="replace_failed:unknown",
            category="internal",
        )
        event_at = time.time()
        await safe_journal_chat_job_finish(
            itgs,
            journal_chat_uid=ctx.journal_chat_uid.encode("utf-8"),
            log_id=ctx.log_id.encode("utf-8"),
            last_event=serialize_journal_chat_event(
                journal_master_key=ctx.journal_master_key,
                event=JournalChatRedisPacketPassthrough(
                    counter=ctx.reserve_event_counter(),
                    type="passthrough",
                    event=EventBatchPacketDataItemDataError(
                        type="error",
                        message="Failed to replace journal entry item",
                        detail="unknown error",
                    ),
                ),
                now=event_at,
            ),
            now=int(event_at),
        )
        raise ValueError("Failed to replace journal entry item")


def _extract_as_text(
    item: JournalEntryItemData,
) -> str:
    assert item.type == "chat", "unknown item type"
    assert item.data.type == "textual", "unknown item data type"
    assert item.data.parts, "empty item"

    assert all(p.type == "paragraph" for p in item.data.parts), "unknown item part type"

    return "\n\n".join(p.value for p in item.data.parts if p.type == "paragraph")


async def _response_pipeline(
    itgs: Itgs,
    /,
    *,
    ctx: JournalChatJobContext,
    greeting: JournalEntryItemData,
    user_message: JournalEntryItemData,
    stats: JournalStats,
) -> AsyncIterable[
    Union[
        Tuple[bool, JournalEntryItemData, JournalEntryItemDataClient],
        Tuple[Literal[None], EventBatchPacketDataItemDataError],
    ]
]:
    await _spinner(itgs, ctx=ctx, message="Running prechecks...")
    text_greeting = _extract_as_text(greeting)
    text_user_message = _extract_as_text(user_message)

    client = openai.OpenAI(api_key=os.environ["OSEH_OPENAI_API_KEY"])
    try:
        # using openai.AsyncOpenAI breaks redis somehow... if you try to ping
        # redis after it, no matter what (even in a fresh connection), it will fail
        # with asyncio.CancelledError
        moderation_response = await asyncio.to_thread(
            client.moderations.create, input=text_user_message
        )
    except Exception as e:
        stats.incr_system_chats_failed_net_unknown(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="moderation",
            category="net",
            detail="unknown",
            error_name=type(e).__name__,
        )
        yield None, EventBatchPacketDataItemDataError(
            type="error",
            message="Failed to connect with LLM",
            detail="moderation error",
        )
        return

    if moderation_response.results[0].categories.self_harm_intent:
        yield True, *_message_from_paragraphs(
            [
                "In a crisis?",
                "Text HELLO to 741741 to connect with a volunteer Crisis Counselor",
                "Free 24/7 support at your fingerprints.",
                "*741741 is a registered trademark of Crisis Text Line, Inc.",
            ]
        )
        return

    if moderation_response.results[0].flagged:
        stats.incr_system_chats_failed_llm(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="moderation",
            category="llm",
            detail="flagged",
        )
        yield None, EventBatchPacketDataItemDataError(
            type="error",
            message="Failed to create response",
            detail="flagged",
        )
        return

    pro_entitlement = await lib.users.entitlements.get_entitlement(
        itgs, user_sub=ctx.user_sub, identifier="pro"
    )
    has_pro = pro_entitlement is not None and pro_entitlement.is_active

    await _spinner(itgs, ctx=ctx, message="Writing initial response...")

    try:
        chat_response = await asyncio.to_thread(
            client.chat.completions.create,
            messages=[
                {
                    "role": "system",
                    "content": "You listen to how users feel and respond with empathy. Your responses should be 3 sentences or fewer. Do not suggest they talk to you, as they will not be able to respond.",
                },
                {"role": "assistant", "content": text_greeting},
                {"role": "user", "content": text_user_message},
            ],
            model=TECHNIQUE_PARAMETERS["model"],
        )
    except Exception as e:
        stats.incr_system_chats_failed_net_unknown(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="chat",
            category="net",
            detail="unknown",
            error_name=type(e).__name__,
        )
        yield None, EventBatchPacketDataItemDataError(
            type="error",
            message="Failed to connect with LLM",
            detail="empathy error",
        )
        return

    empathy_message = chat_response.choices[0].message
    if empathy_message.content is None:
        stats.incr_system_chats_failed_llm(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="chat_initial_empathy",
            category="llm",
            detail="no content",
        )
        yield None, EventBatchPacketDataItemDataError(
            type="error",
            message="Failed to create response",
            detail="no content",
        )
        return

    yield False, *_message_from_text(empathy_message.content)
    await _spinner(itgs, ctx=ctx, message="Searching for free journey...")

    try:
        free_class, free_class_transcript = await select_class(
            itgs,
            ctx=ctx,
            user_message=user_message,
            stats=stats,
            pro=False,
            has_pro=has_pro,
        )
    except ValueError as e:
        yield None, EventBatchPacketDataItemDataError(
            type="error",
            message="Failed to select free journey",
            detail=str(e),
        )
        return

    try:
        chat_response = await asyncio.to_thread(
            client.chat.completions.create,
            messages=[
                {
                    "role": "system",
                    "content": "You should always suggest 1-2 sentences to complete their response. Do not attempt to rewrite their existing response, and do not repeat content from their existing response.",
                },
                {
                    "role": "user",
                    "content": (
                        f"""
Finish my response to a user who wrote

{user_message}

I want to recommend them {free_class.title} by {free_class.instructor.name}. Here's
the transcript of that class

```txt
{str(free_class_transcript)}
```

I need you to add 1-2 sentences to my response so far. Do not include my response in your
message.

{empathy_message.content}
                    """
                    ),
                },
            ],
            model=TECHNIQUE_PARAMETERS["model"],
        )
    except Exception as e:
        stats.incr_system_chats_failed_net_unknown(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="chat_free_class",
            category="net",
            detail="unknown",
            error_name=type(e).__name__,
        )
        yield None, EventBatchPacketDataItemDataError(
            type="error",
            message="Failed to connect with LLM",
            detail="empathy error",
        )
        return

    free_class_message = chat_response.choices[0].message
    if free_class_message.content is None:
        stats.incr_system_chats_failed_llm(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier="chat_free_class",
            category="llm",
            detail="no content",
        )
        yield None, EventBatchPacketDataItemDataError(
            type="error",
            message="Failed to create response",
            detail="no content",
        )
        return

    paragraphs1 = empathy_message.content.split("\n")
    paragraphs1 = [p.strip() for p in paragraphs1]
    paragraphs1 = [p for p in paragraphs1 if p]
    paragraphs2 = free_class_message.content.split("\n")
    paragraphs2 = [p.strip() for p in paragraphs2]
    paragraphs2 = [p for p in paragraphs2 if p]
    paragraphs = paragraphs1 + paragraphs2
    yield True, JournalEntryItemData(
        type="chat",
        data=JournalEntryItemDataDataTextual(
            type="textual",
            parts=[
                *[
                    JournalEntryItemTextualPartParagraph(
                        type="paragraph",
                        value=p,
                    )
                    for p in paragraphs
                ],
                JournalEntryItemTextualPartJourney(
                    type="journey",
                    uid=free_class.uid,
                ),
            ],
        ),
        display_author="other",
    ), JournalEntryItemDataClient(
        type="chat",
        data=JournalEntryItemDataDataTextualClient(
            type="textual",
            parts=[
                *[
                    JournalEntryItemTextualPartParagraph(
                        type="paragraph",
                        value=p,
                    )
                    for p in paragraphs
                ],
                JournalEntryItemTextualPartJourneyClient(
                    details=free_class,
                    type="journey",
                    uid=free_class.uid,
                ),
            ],
        ),
        display_author="other",
    )


@dataclass
class PossibleJourney:
    journey_uid: str
    audio_file_uid: str
    journey_title: str
    journey_description: str
    instructor_name: str
    transcript_uid: str


async def select_class(
    itgs: Itgs,
    /,
    *,
    ctx: JournalChatJobContext,
    user_message: JournalEntryItemData,
    stats: JournalStats,
    pro: bool,
    has_pro: bool,
) -> Tuple[JournalEntryItemTextualPartJourneyClientDetails, Transcript]:
    conn = await itgs.conn()
    cursor = conn.cursor("none")

    responses = await cursor.executeunified3(
        (
            ("SELECT 1 FROM users WHERE sub=?", (ctx.user_sub,)),
            (
                """
WITH 
relevant_journeys(journey_id) AS (
SELECT j.id
FROM journeys AS j
WHERE
    j.deleted_at IS NULL
    AND (? = 0 OR NOT EXISTS (
        SELECT 1 FROM courses, course_journeys
        WHERE
            courses.id = course_journeys.course_id
            AND course_journeys.journey_id = j.id
            AND (courses.flags & 128) = 0
    ))
    AND (? = 0 OR EXISTS (
        SELECT 1 FROM courses, course_journeys
        WHERE
            courses.id = course_journeys.course_id
            AND course_journeys.journey_id = j.id
            AND (courses.flags & 256) <> 0
    ))
    AND j.special_category IS NULL
)
, user_journey_counts_raw(journey_id, cnt) AS (
SELECT
    uj.journey_id,
    COUNT(*)
FROM user_journeys AS uj
WHERE uj.user_id = (SELECT users.id FROM users WHERE users.sub=?)
)
, user_journey_counts(journey_id, cnt) AS (
SELECT
    relevant_journeys.journey_id,
    COALESCE(user_journey_counts_raw.cnt, 0)
FROM relevant_journeys
LEFT OUTER JOIN user_journey_counts_raw ON user_journey_counts_raw.journey_id = relevant_journeys.journey_id
)
SELECT 
    journeys.uid AS d1,
    content_files.uid AS d2,
    journeys.title AS d3,
    journeys.description AS d4,
    instructors.name AS d5,
    transcripts.uid AS d6
FROM 
    user_journey_counts, 
    journeys,
    content_files,
    instructors,
    content_file_transcripts,
    transcripts
WHERE
    user_journey_counts.journey_id = journeys.id
    AND user_journey_counts.cnt = (SELECT MIN(cnt) FROM user_journey_counts)
    AND content_files.id = journeys.audio_content_file_id
    AND content_file_transcripts.id = (
        SELECT cft.id FROM content_file_transcripts AS cft
        WHERE cft.content_file_id = content_files.id
        ORDER BY cft.created_at DESC, cft.uid ASC
    )
    AND content_file_transcripts.transcript_id = transcripts.id
    AND instructors.id = journeys.instructor_id
                """,
                [
                    int(not pro),
                    int(pro),
                    ctx.user_sub,
                ],
            ),
        )
    )

    if not responses[0].results:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier=f"select_class_{'' if pro else 'non_'}pro:user_not_found",
            category="internal",
        )
        raise ValueError(f"User {ctx.user_sub} not found")

    if not responses[1].results:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier=f"select_class_{'' if pro else 'non_'}pro:no_journeys",
            category="internal",
        )
        raise ValueError(f"No journeys found for user {ctx.user_sub}")

    possible_journeys: List[PossibleJourney] = []
    for row in responses[1].results:
        possible_journeys.append(
            PossibleJourney(
                journey_uid=row[0],
                audio_file_uid=row[1],
                journey_title=row[2],
                journey_description=row[3],
                instructor_name=row[4],
                transcript_uid=row[5],
            )
        )

    await _pbar(
        itgs,
        ctx=ctx,
        message=f"Rating {len(possible_journeys)} journeys...",
        at=0,
        of=len(possible_journeys),
    )

    async def get_possible_journey_rating(
        possible_journey: PossibleJourney,
    ) -> Optional[Tuple[float, PossibleJourney]]:
        transcript = await get_transcript(itgs, uid=possible_journey.transcript_uid)
        if transcript is None:
            return None

        text_transcript = str(transcript.to_internal())
        rating_response = await asyncio.to_thread(
            client.chat.completions.create,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "The user provides a message and a journey, and you rate how well "
                        "the journey fits the message from 1 to 10, where 1 means the journey "
                        "would be counterproductive (such as a sleep class when they want to feel awake), "
                        "5 means the journey is unrelated (like a cooking class when they want to talk about their feelings), "
                        "and 10 means the journey is exactly what they need (like a guide to calm when they are feeling anxious)."
                    ),
                },
                {
                    "role": "user",
                    "content": f"""The message is:

```txt
{user_message_text}
```

The journey is:

title: {possible_journey.journey_title}
description: {possible_journey.journey_description}
instructor: {possible_journey.instructor_name}
transcript:

```txt
{text_transcript}
```
""",
                },
            ],
            model=TECHNIQUE_PARAMETERS["model"],
            tools=[
                {
                    "type": "function",
                    "function": {
                        "name": "rate_journey",
                        "description": "Apply the given rating to the journey",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "rating": {
                                    "type": "number",
                                    "description": "The journeys rating from 1 (inclusive) to 10 (inclusive)",
                                    "min": 1,
                                    "max": 10,
                                }
                            },
                            "required": ["rating"],
                        },
                    },
                }
            ],
            tool_choice={"type": "function", "function": {"name": "rate_journey"}},
            max_tokens=2048,
        )

        if not rating_response.choices:
            return None

        rating_message = rating_response.choices[0].message
        if not rating_message.tool_calls or len(rating_message.tool_calls) != 1:
            return None

        rating_arguments_json = rating_message.tool_calls[0].function.arguments
        try:
            rating_arguments = json.loads(rating_arguments_json)
        except Exception:
            return None

        if not isinstance(rating_arguments, dict):
            return None

        rating = rating_arguments.get("rating")
        if not isinstance(rating, (int, float)) or rating < 1 or rating > 10:
            return None

        return rating, possible_journey

    user_message_text = _extract_as_text(user_message)
    rated_journeys: List[Tuple[float, PossibleJourney]] = []
    client = openai.OpenAI(api_key=os.environ["OSEH_OPENAI_API_KEY"])

    running: Set[asyncio.Task] = set()
    concurrency_limit = 10
    next_index = 0
    finished = 0
    _pbar_task: Optional[asyncio.Task] = None

    while running or (next_index < len(possible_journeys)):
        while len(running) < concurrency_limit and next_index < len(possible_journeys):
            running.add(
                asyncio.create_task(
                    get_possible_journey_rating(possible_journeys[next_index])
                )
            )
            next_index += 1

        done, running = await asyncio.wait(running, return_when=asyncio.FIRST_COMPLETED)
        for task in done:
            result = task.result()
            if result is not None:
                rated_journeys.append(result)

        finished += len(done)
        if _pbar_task is not None and _pbar_task.done():
            await _pbar_task
            _pbar_task = None
        if _pbar_task is None:
            _pbar_task = asyncio.create_task(
                _pbar(
                    itgs,
                    ctx=ctx,
                    message=f"Rating {len(possible_journeys)} journeys...",
                    at=finished,
                    of=len(possible_journeys),
                )
            )

    if _pbar_task is not None:
        await _pbar_task
    del _pbar_task

    if not rated_journeys:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier=f"select_class_{'' if pro else 'non_'}pro:no_rated_journeys",
            category="internal",
        )
        raise ValueError(f"No rated journeys found for user {ctx.user_sub}")

    best_rating = max(rated_journeys, key=lambda x: x[0])[0]
    eligible_journeys = [
        journey for rating, journey in rated_journeys if rating >= best_rating - 2
    ]

    async def _compare(a: PossibleJourney, b: PossibleJourney) -> int:
        """Compares two possible journeys using the llm"""
        transcript1 = await get_transcript(itgs, a.transcript_uid)
        transcript2 = await get_transcript(itgs, b.transcript_uid)

        if transcript1 is None and transcript2 is None:
            return random.choice([-1, 1])
        if transcript1 is None:
            return 1
        if transcript2 is None:
            return -1

        a_id = make_id(a.journey_title)
        b_id = make_id(b.journey_title)

        if a_id == b_id or a_id == "" or b_id == "":
            a_id = a.journey_uid
            b_id = b.journey_uid

        if a_id == b_id:
            return random.choice([-1, 1])

        comparison_response = await asyncio.to_thread(
            client.chat.completions.create,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "The user provides a message and two journeys. You determine which journey is a better "
                        "fit for the message. A better fit is one that is more relevant to the user's needs."
                    ),
                },
                {
                    "role": "user",
                    "content": f"""The message is:

```txt
{user_message_text}
```

The first journey is:

id: {a_id}
title: {a.journey_title}
description: {a.journey_description}
instructor: {a.instructor_name}
transcript:

```txt
{str(transcript1.to_internal())}
```

The second journey is:

id: {b_id}
title: {b.journey_title}
description: {b.journey_description}
instructor: {b.instructor_name}
transcript:

```txt
{str(transcript2.to_internal())}
```
""",
                },
            ],
            model=TECHNIQUE_PARAMETERS["model"],
            tools=[
                {
                    "type": "function",
                    "function": {
                        "name": "select_journey",
                        "description": "Select the given journey as the preferred journey",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "id": {
                                    "type": "string",
                                    "description": "The ID of the journey which is preferred amongst the two",
                                }
                            },
                            "required": ["id"],
                        },
                    },
                }
            ],
            tool_choice={"type": "function", "function": {"name": "select_journey"}},
            max_tokens=2048,
        )

        if not comparison_response.choices:
            return random.choice([-1, 1])

        comparison_message = comparison_response.choices[0].message
        if not comparison_message.tool_calls or len(comparison_message.tool_calls) != 1:
            return random.choice([-1, 1])

        comparison_arguments_json = comparison_message.tool_calls[0].function.arguments
        try:
            comparison_arguments = json.loads(comparison_arguments_json)
        except Exception:
            return random.choice([-1, 1])

        if not isinstance(comparison_arguments, dict):
            return random.choice([-1, 1])

        selected_id = comparison_arguments.get("id")
        if not isinstance(selected_id, str):
            return random.choice([-1, 1])

        if selected_id == a_id:
            return -1
        if selected_id == b_id:
            return 1
        return random.choice([-1, 1])

    num_comparisons = 0
    _spinner_task = cast(Optional[asyncio.Task], None)

    async def _compare_with_progress(a: PossibleJourney, b: PossibleJourney) -> int:
        nonlocal num_comparisons, _spinner_task

        result = await _compare(a, b)
        num_comparisons += 1
        if _spinner_task is not None and _spinner_task.done():
            await _spinner_task
            _spinner_task = None
        if _spinner_task is None:
            _spinner_task = asyncio.create_task(
                _spinner(
                    itgs,
                    ctx=ctx,
                    message=f"Ranking top {len(eligible_journeys)} pairwise...",
                    detail=f"Comparisons so far: {num_comparisons}",
                )
            )
        return result

    sorted_journeys = await merge_insertion_sort(
        eligible_journeys, compare=_compare_with_progress
    )
    if _spinner_task is not None:
        await _spinner_task
    del _spinner_task

    await _spinner(
        itgs, ctx=ctx, message=f"Finishing up (total comparisons: {num_comparisons})..."
    )

    best_journey = sorted_journeys[0]
    response = await cursor.execute(
        """
SELECT
    journeys.uid,
    journeys.title,
    journeys.description,
    darkened_image_files.uid,
    content_files.duration_seconds,
    instructors.name,
    instructor_profile_pictures.uid,
    (SELECT MAX(uj.created_at) FROM user_journeys AS uj WHERE uj.journey_id = journeys.id AND uj.user_id = (SELECT users.id FROM users WHERE users.sub=?)) AS last_taken_at,
    (SELECT ul.created_at FROM user_likes AS ul WHERE ul.journey_id = journeys.id AND ul.user_id = (SELECT users.id FROM users WHERE users.sub=?)) AS liked_at
FROM 
    journeys, 
    image_files AS darkened_image_files, 
    content_files, 
    instructors
LEFT OUTER JOIN image_files AS instructor_profile_pictures ON instructor_profile_pictures.id = instructors.picture_image_file_id
WHERE
    journeys.uid = ?
    AND journeys.deleted_at IS NULL
    AND darkened_image_files.id = journeys.darkened_background_image_file_id
    AND content_files.id = journeys.audio_content_file_id
    AND instructors.id = journeys.instructor_id
        """,
        (ctx.user_sub, ctx.user_sub, best_journey.journey_uid),
    )
    if not response.results:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier=f"select_class_{'' if pro else 'non_'}pro:journey_not_found",
            category="internal",
        )
        raise ValueError(f"Journey {best_journey.journey_uid} not found")

    row = response.results[0]
    access = (
        "free"
        if not pro
        else ("paid-requires-upgrade" if not has_pro else "paid-unlocked")
    )

    transcript = await get_transcript(itgs, best_journey.transcript_uid)
    if transcript is None:
        stats.incr_system_chats_failed_internal(
            unix_date=ctx.queued_at_unix_date_in_stats_tz,
            **TECHNIQUE_PARAMETERS,
            prompt_identifier=f"select_class_{'' if pro else 'non_'}pro:transcript_not_found",
            category="internal",
        )
        raise ValueError(
            f"Transcript for journey {best_journey.journey_uid} not found after selection"
        )

    return (
        JournalEntryItemTextualPartJourneyClientDetails(
            uid=row[0],
            title=row[1],
            description=row[2],
            darkened_background=ImageFileRef(
                uid=row[3],
                jwt=await lib.image_files.auth.create_jwt(
                    itgs,
                    image_file_uid=row[3],
                ),
            ),
            duration_seconds=row[4],
            instructor=MinimalJourneyInstructor(
                name=row[5],
                image=(
                    None
                    if row[6] is None
                    else ImageFileRef(
                        uid=row[6],
                        jwt=await lib.image_files.auth.create_jwt(
                            itgs,
                            image_file_uid=row[6],
                        ),
                    )
                ),
            ),
            last_taken_at=row[7],
            liked_at=row[8],
            access=access,
        ),
        transcript.to_internal(),
    )


T = TypeVar("T")
V = TypeVar("V")
Q = TypeVar("Q")


async def merge_insertion_sort(
    arr: List[T], /, *, compare: Callable[[T, T], Awaitable[int]], concurrency: int = 10
) -> List[T]:
    """Performs a Merge-insertion sort on the given array, assuming that
    comparisons are expensive and not necessarily consistent, and thus
    never asks for the same (or symmetric) comparisons (via caching)

    A merge-insertion sort, aka the Ford-Johnson algorithm, is a hybrid
    sort intended to minimize the number of comparisons.

    I didn't make an effort to prove this, but I think it's fair to reason
    that an algorithm which minimizes the # of comparisons will not check
    inferrable comparisons (e.g. if A < B and B < C, then A < C), and thus
    the fact that the comparison function does not necessarily produce a
    partial order is not a problem. Regardless, this definitely terminates
    """
    # Implementation based on https://gist.github.com/DominikPeters/469134edd03c1479641ab3c252111cb3
    # This isn't a very space or time efficient implementation, but since only
    # the # of comparisons really matters, thats fine
    known_comparisons: Dict[Tuple[int, int], int] = dict()

    async def _compare(a_index: int, b_index: int) -> int:
        known_a_to_b = known_comparisons.get((a_index, b_index))
        if known_a_to_b is not None:
            return known_a_to_b

        comparison = await compare(arr[a_index], arr[b_index])
        known_comparisons[(a_index, b_index)] = comparison
        known_comparisons[(b_index, a_index)] = -comparison

        return comparison

    async def _binary_insert(
        seq: List[V], x: V, less: Callable[[V, V], Awaitable[bool]]
    ) -> int:
        possible_positions = range(len(seq) + 1)
        L, R = 0, possible_positions[-1]
        while len(possible_positions) > 1:
            m = (L + R) // 2
            if await less(x, seq[m]):
                R = m
            else:
                L = m + 1
            possible_positions = [p for p in possible_positions if L <= p <= R]
        return possible_positions[0]

    async def _merge_insertion(
        seq: List[V], less: Callable[[V, V], Awaitable[bool]]
    ) -> List[V]:
        if len(seq) <= 1:
            return seq

        async def _augmented_less(returnv: Q, x: V, y: V) -> Tuple[Q, bool]:
            return returnv, await less(x, y)

        comparisons: List[Optional[bool]] = [None for _ in range(len(seq) // 2)]
        running: Set[asyncio.Task] = set()

        for idx, (x1, x2) in enumerate(zip(seq[::2], seq[1::2])):
            if len(running) >= concurrency:
                done, running = await asyncio.wait(
                    running, return_when=asyncio.FIRST_COMPLETED
                )
                for task in done:
                    task_result = task.result()
                    comparisons[task_result[0]] = task_result[1]

            running.add(asyncio.create_task(_augmented_less(idx, x1, x2)))

        await asyncio.wait(running, return_when=asyncio.ALL_COMPLETED)
        for task in running:
            task_result = task.result()
            comparisons[task_result[0]] = task_result[1]

        pairs: List[Tuple[V, V]] = []
        for x1, x2, less_result in zip(seq[::2], seq[1::2], comparisons):
            assert less_result is not None
            if less_result:
                pairs.append((x1, x2))
            else:
                pairs.append((x2, x1))

        pairs = await _merge_insertion(pairs, less=lambda a, b: less(a[1], b[1]))
        out = [x2 for x1, x2 in pairs]
        remaining = cast(List[Tuple[V, Union[V, Literal["END"]]]], pairs[:])
        if len(seq) % 2 == 1:
            remaining.append((seq[-1], "END"))
        out.insert(0, remaining.pop(0)[0])
        buckets = [2, 2]
        power_of_2 = 4
        while sum(buckets) < len(remaining):
            power_of_2 *= 2
            buckets.append(power_of_2 - buckets[-1])
        reordered = []
        last_index = 0
        for bucket in buckets:
            reordered += reversed(remaining[last_index : last_index + bucket])
            last_index += bucket
        for y, x in reordered:
            if x == "END":
                out.insert(await _binary_insert(out, y, less), y)
            else:
                out.insert(await _binary_insert(out[: out.index(x)], y, less), y)
        return out

    async def _less(a: int, b: int) -> bool:
        return await _compare(a, b) < 0

    sorted = await _merge_insertion(list(range(len(arr))), less=_less)
    return [arr[i] for i in sorted]


def make_id(v: str) -> str:
    return "".join(
        c
        for c in v.replace(" ", "_").lower()
        if c in string.ascii_lowercase or c == "_"
    )
